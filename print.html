<!DOCTYPE HTML>
<html lang="en" class="thoughtassault sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>thoughtassault-blog</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "thoughtassault";
            const default_dark_theme = "navy";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('thoughtassault')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="thoughtassault">Thoughtassault</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">thoughtassault-blog</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="hello"><a class="header" href="#hello">Hello</a></h1>
<p>My name is Dora, and I am a software developer from Turkey. I live in London.</p>
<p><a href="https://twitter.com/alleinany">twitter</a> - <a href="https://github.com/akbulutdora">github</a> - <a href="https://snort.social/p/npub18gpgwcqdam4nsde4e6gsuclv8cqyxhjwzxfarskfr5e9qyq97aqqtnch39">snort</a></p>
<hr />
<h2 id="education"><a class="header" href="#education">Education</a></h2>
<h3 id="msc---city-st-georges-university-of-london"><a class="header" href="#msc---city-st-georges-university-of-london">MSc - <strong>City St. George's, University of London</strong></a></h3>
<p><em>(Present)</em>
MSc in Computer Game Technologies with VR</p>
<h3 id="undergrad---sabanci-university"><a class="header" href="#undergrad---sabanci-university">Undergrad - <strong>Sabanci University</strong></a></h3>
<p><em>(January 2023)</em></p>
<p>BSc in Computer Science - 4.00 GPA - First ranking student</p>
<p>Minor in Philosophy</p>
<hr />
<h2 id="work-experience"><a class="header" href="#work-experience">Work Experience</a></h2>
<h3 id="full-stack-phplaravel-developer--freelance"><a class="header" href="#full-stack-phplaravel-developer--freelance"><strong>Full Stack PHP/Laravel Developer</strong> @ <strong>Freelance</strong></a></h3>
<p><em>(March 2025 - Present)</em>
I develop bespoke web and mobile apps for businesses. I use Laravel/PHP for web and Flutter or React Native for mobile. Sometimes I do this with friends and sometimes alone. I worked on Meti-Box last year, and right now I'm working on Meti-Bills and Musiki FM.</p>
<h3 id="full-stack-phplaravel-developer--net-koruma"><a class="header" href="#full-stack-phplaravel-developer--net-koruma"><strong>Full Stack PHP/Laravel Developer</strong> @ <strong>Net Koruma</strong></a></h3>
<p><em>(September 2023 - March 2025)</em></p>
<p><a href="https://www.netkoruma.com/">Net Koruma</a> is a B2B anti-phishing solution. We find phishing online and report them to relevant authorities. I found this to be a very valuble and ethical business. My responsibilities were basically everything. Optimizations, new features, automatization of tasks to relieve the burden of the analysts.</p>
<p>I worked on scrapers, facebook ad library, instagram mobile app, and more.</p>
<h3 id="mobile-developer--upcarta"><a class="header" href="#mobile-developer--upcarta"><strong>Mobile developer</strong> @ <strong>Upcarta</strong></a></h3>
<p><em>(March 2022 - September 2023)</em></p>
<p><a href="https://www.upcarta.com/">Upcarta</a> is a platform for discovering, organizing and sharing content. Its killer feature is gathering scattered content recommendations, curations and collections from all around the web, streamlining the process of discovering content. I have a strong belief that what matters to humans will be humans they care about.</p>
<p>For the past year, I have been developing the mobile app of Upcarta. We use Flutter.</p>
<p>I learned Flutter all by myself and taught the rest of the team on the go. I had to make the architectural and stylistic decisions because flutter didn't/doesn't really have the idiomatic ways to guide us. It was quite a challenge.</p>
<p>One thing that made everything too difficult was the "Clean Code" advice we found on the internet as complete beginners. It overcomplicated things and we didn't know what we were doing for a long time. I would do things very differently today.</p>
<p>Upcarta is on the app stores.</p>
<h3 id="visiting-researcher-intern--university-of-kent"><a class="header" href="#visiting-researcher-intern--university-of-kent"><strong>Visiting Researcher Intern</strong> @ <strong>University of Kent</strong></a></h3>
<p><em>(Summer 2022)</em></p>
<p>At Kent, I was responsible with implementing a tool to collect data about DDoS protection adoption across the internet. I used Go, MongoDB and GCC.
Since the tool was meant to scan the a huge number of domains weekly, it had to be performant. I benchmarked several approaches and libraries.</p>
<p>During the internship, I discovered my interest in programming languages and explored the academic life. I love learning new programming syntax, semantics and paradigms.</p>
<h3 id="nlp-intern--yazi-ai"><a class="header" href="#nlp-intern--yazi-ai"><strong>NLP Intern</strong> @ <strong>YAZI AI</strong></a></h3>
<p><em>(Summer 2021)</em></p>
<p>This project aimed to be a pioneer in Turkish NLP, as it was one of the first works on Turkish Financial Sentiment Analysis. I built scrapers for financial news websites and stock market movements. Then I tried to apply NER to the data I collected. The internship ended due to time constraints before I could complete the project.
I worked with Python.</p>
<p>I was completely inexperienced and mostly confused. I was very dependent on my supervisor and she was quite busy, so things did not really go as I wanted them to go.</p>
<hr />
<h2 id="today"><a class="header" href="#today">Today</a></h2>
<p>I am working as a freelance software developer and my game Mania. I am using Odin and Raylib to make my game. The main goals are (1) become a great programmer and (2) make this a beautiful, real game.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="1-passing-messages-between-threads"><a class="header" href="#1-passing-messages-between-threads">1. Passing messages between threads</a></h1>
<p>I am trying to implement simple message-passing channels in Rust. I want to share/log my learning progress. I think it will be fun to return to it in some months/years.</p>
<p><strong>Note:</strong> I am a complete beginner to Rust and haven't dealt with this sort of concurrency before.</p>
<p>The task is simple: I will have two channels running on different threads or running as concurrent processes.
One of them will be the client, asking for the amount of ice cream the server has. Client's actions can be triggered by command line inputs.</p>
<p>The server will tell the client how much ice cream it has. The ice cream is 1kg to begin with, and melts by 10g each second. Bonus: each question can decrease the amount of ice cream by 20g. This will force the server to implement some kind of concurrent operation handling.</p>
<h2 id="first-try"><a class="header" href="#first-try">First try</a></h2>
<p>I read <a href="https://tokio.rs/tokio/tutorial/channels">tokio docs</a>. I initialize the channel, and pass the transmitter and receiver to the tasks I spawn in the main thread (which felt intuitive). But the program immediately ends. No messages after the initial "Let's go!" are printed.</p>
<pre><code class="language-rust">use tokio::sync::mpsc;

#[tokio::main]
async fn main() {
    println!("Let's go!");
    // Create the channel
    let (tx, rx) = mpsc::channel(8);
    // Spawn the server task.
    tokio::spawn(run_server(rx));

    // Spawn the client task.
    tokio::spawn(run_client(tx));
}

async fn run_server(mut rx: mpsc::Receiver&lt;String&gt;) {
    println!("running server");
    while let Some(message) = rx.recv().await {
        println!("GOT = {}", message);
    }
}

async fn run_client(tx: mpsc::Sender&lt;String&gt;) {
    println!("sending from first handle");
    // wait for 2 seconds
    tokio::time::sleep(tokio::time::Duration::from_secs(2)).await;
    println!("woke up from sleep");

    tx.send("sending from first handle".to_owned())
        .await
        .unwrap();
}</code></pre>
<p>I think the problem with this was that my program was not waiting for any of the tasks I spawned. It just started the threads, and there was nothing else to do, so it returned.</p>
<h2 id="second-try"><a class="header" href="#second-try">Second try</a></h2>
<p>Run the server in the main thread and wait for it to complete. This works, but I think I am blocking the main thread with the server.</p>
<p>Also I got the intuition that once the function owning the transmitter (client) returns, it is dropped, so the channel is closed.</p>
<pre><code class="language-rust">use tokio::sync::mpsc;

#[tokio::main]
async fn main() {
    println!("Let's go!");
    let (tx, rx) = mpsc::channel(8);
    // Spawn the client task.
    tokio::spawn(run_client(tx));

    // the server is running, but it blocks
    _run_server(rx).await;
}

// we do not use this function in this version
async fn _run_server(mut rx: mpsc::Receiver&lt;String&gt;) {
    println!("running server");
    while let Some(msg) = rx.recv().await {
        println!("received: {:?}", msg);
    }
}

async fn run_client(tx: mpsc::Sender&lt;String&gt;) {
    // wait for 2 seconds
    tokio::time::sleep(tokio::time::Duration::from_secs(2)).await;
    let msg = String::from("Hello ice cream guy");
    tx.send(msg).await.expect("can not send user on channel");
}</code></pre>
<h2 id="third-try"><a class="header" href="#third-try">Third try</a></h2>
<p>I spawn a new task for the server and wait for it to complete. This works, but I don't really understand why. I don't know if I am blocking the main thread as well. I also feel like there is a cleaner way to do this. Added understanding this thoroughly to my task.</p>
<pre><code class="language-rust">use tokio::sync::mpsc;

#[tokio::main]
async fn main() {
    println!("Let's go!");
    let (tx, rx) = mpsc::channel(8);
    // Spawn the client task.
    tokio::spawn(run_client(tx));

    // Spawn the server task in a way it doesnt block the main thread
    tokio::spawn(async move {
        run_server(rx).await;
    })
    .await
    .unwrap();
}

// we do not use this function in this version
async fn run_server(mut rx: mpsc::Receiver&lt;String&gt;) {
    println!("running server");
    while let Some(msg) = rx.recv().await {
        println!("received: {:?}", msg);
    }
}

async fn run_client(tx: mpsc::Sender&lt;String&gt;) {
    // wait for 2 seconds
    tokio::time::sleep(tokio::time::Duration::from_secs(2)).await;

    let msg = String::from("Hello ice cream guy");

    tx.send(msg).await.expect("can not send user on channel");
}</code></pre>
<p><strong>Minor update:</strong> I confirmed my hunch that when the function using the transmitter returns, the channel is closed.</p>
<p>While trying to learn about this, I read <a href="https://doc.rust-lang.org/book/ch16-02-message-passing.html">something on the Rust book</a> that excited me:</p>
<blockquote>
<p>One increasingly popular approach to ensuring safe concurrency is message passing, where threads or actors communicate by sending each other messages containing data.
Here’s the idea in a slogan from the Go language documentation: <em>“Do not communicate by sharing memory; instead, share memory by communicating.”</em></p>
</blockquote>
<p>I love Go, and seeing a wink to its docs made my day.</p>
<h2 id="final-attempt"><a class="header" href="#final-attempt">Final attempt</a></h2>
<p>I did some improvements and kinda nailed the task. The #rustlang discord community helped me.</p>
<p>I learned from them a couple of things:</p>
<ol>
<li>
<p>I should await the tasks, so that the program will wait for them to complete. In order for them not to block the main thread, I should spawn the tasks, and await the futures returned by the tasks somewhere else. Any code that will run in the main thread should run in between.</p>
</li>
<li>
<p>I could also use <code>join!</code>, but that's overkill because it's used for lazy futures, and tokio starts the tasks immediately. Therefore awaiting them in series is enough and idiomatic.</p>
</li>
</ol>
<p>I didn't understand when to use <code>join!</code> exactly, but I understand what's going on with my code.</p>
<p>Here is what I did with what I've learnt:</p>
<pre><code class="language-rust">use tokio::sync::{mpsc, oneshot};
use tokio::time::{self, Duration, Instant};

#[tokio::main]
async fn main() {
    println!("Let's go!");
    let (tx, rx) = mpsc::channel(8);

    let client = tokio::spawn(run_client(tx));
    let server = tokio::spawn(run_server(rx));

    client.await.unwrap();
    server.await.unwrap(); // The main thread will not return until server returns. 
}</code></pre>
<p><strong>Receiving responses:</strong></p>
<p>I wanted the clients to be able to send requests and receive responses to those. I accidentally asked GPT to tell me how receive responses from the server so it recommended me to use oneshot channels. So I created a ClientRequest to be sent.</p>
<pre><code class="language-rust">#[derive(Debug)]
struct ClientRequest {
    message: String,
    tx: oneshot::Sender&lt;String&gt;,
}</code></pre>
<p><strong>The server:</strong>
Ice cream melts. I added this to see how data processing within the server could be a part of the whole message exchanging program. I had seen the <code>interval.tick</code> before, but Copilot completed the piece of code that ticks the timer. I will learn about how that works.</p>
<pre><code class="language-rust">async fn run_server(mut rx: mpsc::Receiver&lt;ClientRequest&gt;) {
    println!("SERVER; I will give one person some ice cream!");
    let mut ice_cream_amount = 50;
    let mut interval = time::interval_at(
        Instant::now() + Duration::from_secs(1),
        time::Duration::from_secs(1),
    );

    loop {
        tokio::select! {
            _ = interval.tick() =&gt; {
                if ice_cream_amount &lt; 10 {
                    println!("SERVER; no more ice cream!");
                    return;
                }
                ice_cream_amount -= 10;
            }
            Some(ClientRequest { message, tx }) = rx.recv() =&gt; {
                println!("SERVER; received: {:?}", message);

                let response = format!("Here is your ice cream! I have {ice_cream_amount} left!");
                tx.send(response).unwrap();
            }
            else =&gt; {
                println!("SERVER; I don't know what's happening here!");
                break;
            }
        }
    }
}</code></pre>
<p><strong>Client:</strong></p>
<p>Every two seconds, the client will ask the server for ice cream, and report how much ice cream is left. It creates a oneshot channel and passes it to the server for an answer. It is blocked until the server responds.</p>
<pre><code class="language-rust">async fn run_client(tx: mpsc::Sender&lt;ClientRequest&gt;) {
    loop {
        tokio::time::sleep(tokio::time::Duration::from_secs(2)).await;
        if tx.is_closed() {
            println!("CLIENT; Ice cream guy is gone! I guess I will go home now.");
            return;
        }
        let (response_tx, response_rx) = oneshot::channel();
        let new_msg = ClientRequest {
            message: String::from("Hello ice cream guy, give me ice cream!"),
            tx: response_tx,
        };
        tx.send(new_msg)
            .await
            .expect("can not send user on channel");

        let answer = response_rx.await.unwrap();
        println!("CLIENT; I knew you loved me!: {:?}", answer);
    }
}</code></pre>
<p>I might work on a more complicated implementation by adding the following:</p>
<ul>
<li>There are more than one clients, and each time the clients ask for ice cream, the amount of ice cream decreases.</li>
<li>The client's are not blocked when they are waiting for a response from the server.</li>
</ul>
<p>Another insight I gained due to the help of a Rust developer was that the Go idiom I mentioned was more than a best practice in Rust. The compiler has strict constraints on how data can be modified by different threads.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="2-improvement-to-message-passing-requesting-arbitrary-data"><a class="header" href="#2-improvement-to-message-passing-requesting-arbitrary-data">2. Improvement to message passing: Requesting arbitrary data</a></h1>
<p>In the previous exercise, I implemented a simple program where a client and server ran asynchronously and communicated by passing messages. This time, the client will send arbitrary queries to the server to execute.</p>
<hr />
<h2 id="design"><a class="header" href="#design">Design</a></h2>
<h3 id="server"><a class="header" href="#server">Server</a></h3>
<ul>
<li>The server holds a mutable database. To keep things simple, this is a simple data structure. There is information about the ice cream the server has such as the existing flavors, their recipes, existing orders and which flavors they are in, etc. The database fields are as follows:
<ul>
<li><code>flavors_stock: Vec&lt;String&gt;</code> -&gt; represents the flavors in stock.</li>
<li><code>flavor_recipes: HashMap&lt;String, Vec&lt;String&gt;&gt;</code> -&gt; represents the recipes of each flavor (it is guaranteed that the existing flavors can only be flavors from this list).</li>
<li>I can add more later if I like.</li>
</ul>
</li>
<li>The database is initialized upon <code>run_server()</code>. When it receives a request, it calls the closure sent with the request on the database.</li>
<li>The server doesn't deal with error handling. It returns a <code>Result</code> to the client. The content of the result will be of the generic type passed from the client.</li>
</ul>
<h3 id="client"><a class="header" href="#client">Client</a></h3>
<ul>
<li>The client sends queries to the server. The <code>ClientRequest</code> consists of a one-shot channel and query. The query is a <code>FnOnce</code> function that takes the server's data as a reference (<code>&amp;Database</code>), and the return type is arbitrary. I think I can achieve this using a generic type and trait bounds (Even though I understand generics, trait objects and traits, I still need to figure this out).</li>
<li>For example, the client can query the database for how many different flavors it has (integer), which flavors do not have dairy in their recipes (list of strings), and more.</li>
</ul>
<p>A simple diagram of the communication process I made GPT draw for me:</p>
<pre><code>+---------+                           +--------+
|         | --(1) Prepare Query-----&gt; |        |
|  Client |                           | Server |
|         |                           |        |
+---------+                           +--------+
                                       |
                                       V
                             (2) Execute Query on Database
                                       |
                                       V
+---------+                           +--------+
|         | &lt;---(3) Send Result ----- |        |
|  Client |                           | Server |
|         |                           |        |
+---------+                           +--------+

</code></pre>
<hr />
<h2 id="implementation"><a class="header" href="#implementation">Implementation</a></h2>
<h3 id="first-attempt"><a class="header" href="#first-attempt">First attempt</a></h3>
<p>The <code>Query</code> struct and its methods lie at the heart of this task. So let's take a look at my first implementation:</p>
<pre><code class="language-rust">pub struct Query {
    tx: oneshot::Sender&lt;Box&lt;dyn Any + Send&gt;&gt;,
    f: Box&lt;dyn FnMut(&amp;Database) -&gt; Box&lt;dyn Any + Send&gt; + Send&gt;,
}

impl Query {
    // used by the server
    pub fn execute(mut self, database: &amp;Database) {
        let result = (self.f)(database);
        let _ = self.tx.send(result);
    }

    // used by the client
    pub fn new&lt;F&gt;(f: F) -&gt; (Self, oneshot::Receiver&lt;Box&lt;dyn Any + Send&gt;&gt;)
    where
        F: FnMut(&amp;Database) -&gt; Box&lt;dyn Any + Send&gt; + Send + 'static,
    {
        let (tx, rx) = oneshot::channel();
        let f = Box::new(f);
        let query = Self { tx, f };

        (query, rx)
    }
}</code></pre>
<p>My first approach was to have the one-shot channel and closure that is sent as fields of the query. This felt natural and intuitive. The client creates a <code>Query</code> using the <code>new</code> constructor, boxes the closure to store it and returns the query as well as the one-shot channel for the response. The role of the server is to execute the given closure. The execute method is also responsible for sending the result back to the client, so the server is completely blind to the inner workings of the query or the client. But this created an indirect and verbose implementation.</p>
<p>I could implement the server as I expected: But the client side didn't go as expected. It worked, but it was not simple at all.</p>
<pre><code class="language-rust">let f: Box&lt;dyn FnMut(&amp;Database) -&gt; Box&lt;dyn Any + Send&gt; + Send&gt; =
    Box::new(move |database: &amp;crate::server::Database| {
        Box::new(database.flavor_recipes.contains_key(&amp;Flavor::Chocolate))
    });
let (new_msg, response_rx) = Query::new(f);
tx.send(new_msg)
    .await
    .expect("can not send user on channel");

match response_rx.await {
    Ok(value) =&gt; {
        // Here, `value` is a `Box&lt;dyn Any + Send&gt;`. You'll have to downcast it
        // to the type you know it should be (in this case, `bool`), and handle
        // the case where it's not the type you expected.
        match value.downcast_ref::&lt;bool&gt;() {
            Some(b) =&gt; {
                println!("CLIENT; received response: {}", b);
            }
            None =&gt; {
                println!("CLIENT; received response of unexpected type");
            }
        }
    }
}</code></pre>
<p>Notice the chaos and verbosity I had to go through to (1) create the closure to the query and (2) downcast the response. The first problem could be sorted out to one degree by moving the boxing operation into the query constructor, but the second will not be handled like this.</p>
<p>I had a discussion with my senior <a href="https://github.com/TylerBloom">Tyler</a> to overcome this issue. The actual purpose of these tasks is to learn Rust and contribute to Tyler's open-source project, <a href="https://github.com/MonarchDevelopment">Monarch Development</a>. Our discussion was fruitful, let me summarize the main points and what I've learned.</p>
<ol>
<li>Usage of <code>Any</code> indeed brings verbosity and complication. The way to figure that out goes by changing the signature of the <code>Query::new()</code> constructor and giving it generic types.</li>
</ol>
<p>I got his advice wrong (now I see what I did wrong clearer) and went for changing the Query struct instead. I had three approaches (all of which were wrong):</p>
<ol>
<li>Make the <code>Query</code> struct generically typed: This resulted in a hugely verbose <code>run_client</code> and <code>run_server</code> function signature, not helping with downcasting from <code>Any</code>even a bit.</li>
</ol>
<pre><code class="language-rust">pub async fn run_client(tx: mpsc::Sender&lt;Query&lt;Result&lt;Box&lt;dyn Any + Send&gt;, QuError&gt;&gt;&gt;)</code></pre>
<ol start="2">
<li>Having different flavors for the <code>Query</code>, making it an enum would also not be as good as it introduced another type of complexity to the program.</li>
</ol>
<pre><code class="language-rust">struct FlavorExistsQuery;
struct FlavorCountQuery;
struct FlavorWithoutMilkQuery;</code></pre>
<p>This was when Tyler told me that Query was at the heart of the problem. <code>Query</code> should not have a generic type, and they told me to think more from the perspective of the server and move more of the logic into the closure I box. Here, we are done with the first attempt. You can find the source code <a href="https://github.com/akbulutdora/rust-learning-projects/tree/9c46a484135707c3cac8bce9308289b6f9b8eb0e/008.%20rust-icecream-db-query/icecream-db-query">here</a>. Now we come to the solution.</p>
<h3 id="second-attempt"><a class="header" href="#second-attempt">Second attempt</a></h3>
<p>I was very surprised and excited at the solution.</p>
<pre><code class="language-rust">pub struct Query {
    execute_and_send: Box&lt;dyn FnOnce(&amp;Database) + Send&gt;,
}

/// [Query::new] constructor needs to take a closure of type [FnOnce(&amp;Database) -&gt; T + Send + 'static]
/// it should return a receiver as well as the query object
impl Query {
    // used by the client
    pub fn new&lt;T, F&gt;(f: F) -&gt; (Self, oneshot::Receiver&lt;T&gt;)
    where
        F: FnOnce(&amp;Database) -&gt; T + Send + 'static,
        T: Debug + Send + 'static,
    {
        let (tx, rx) = oneshot::channel();
        let execute_and_send = Box::new(move |database: &amp;Database| {
            let result = f(database);
            let _ = tx.send(result);
        });
        let query = Self { execute_and_send };

        (query, rx)
    }

    // used by the server
    pub fn execute(self, database: &amp;Database) {
        (self.execute_and_send)(database);
    }
}</code></pre>
<p>The query constructor takes a closure and wraps it into another closure. The latter executes the former, sends the result through the channel and returns nothing. This way, we can avoid using any generic types or trait objects in the <code>Query</code> struct. This is a very flexible and clear design!</p>
<p>Now both the client and server codes are much simpler.</p>
<p>Client:</p>
<pre><code class="language-rust">let (q, response_rx) =
        Query::new(|database: &amp;Database| database.flavor_recipes.contains_key(&amp;Flavor::Chocolate));
    tx.send(q).await.expect("CLIENT; can not send on channel");
    match response_rx.await {
        Ok(value) =&gt; println!(
            "CLIENT; I asked if he has chocolate flavor! He said {}",
            value
        ),
        Err(e) =&gt; println!("CLIENT; failed to receive response: {:?}", e),
    }</code></pre>
<p>Server:</p>
<pre><code class="language-rust">//...
Some(query) = rx.recv() =&gt; query.execute(&amp;mut database),
//...</code></pre>
<p>I think this is a very elegant solution. I don't find it very intuitive yet: It feels like bending my head and looking at the world upside down, but I find the challenge of digesting this exciting.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="3-designing-and-implementing-a-generic-actor-model-for-concurrency"><a class="header" href="#3-designing-and-implementing-a-generic-actor-model-for-concurrency">3. Designing and Implementing a Generic Actor Model for Concurrency</a></h1>
<p>The message-passing method I implemented in the previous chapter is very interesting to me. Now we are taking another step forward and implementing a generic Actor Model for SquireBot. This could be extended into a crate in the future.</p>
<p>As Tyler suggested, we start with defining how we want the user experience to look like.
Here is how it could look like:</p>
<pre><code class="language-rust">#[tokio::main]
async fn main() {
    // First possible API for initializing the client and the actor
    // The client spawns the Actor task as well.
    let client = client::Client::new(0, action);

    // Second possible API for initializing the client and the actor
    // The ActorBuilder creates the Actor and client, and spawns the Actor when called.
    // let client = actor::ActorBuilder::create().spawn();

    let data = 5;
    let (tracker, message) = Message::create(&amp;data);
    client.send(message);

    let result = tracker.await;
    match result {
        Ok(val) =&gt; println!("tracker: {val}"),
        Err(err) =&gt; println!("tracker: err: {}", err),
    }
}</code></pre>
<ol>
<li>Since we are approaching the problem from the perspective of the users, let's play the game in our heads a bit. Some users might want the actors to communicate between each other, so more fine-grained control could be desirable. Therefore we thought of providing the users more than one way to initialize <code>Actor</code>s and <code>Client</code>s. In the first one, we are initializing the client and leaving the initialization of the actor to the client's constructor. This allows the users to avoid interacting with the <code>Actor</code> completely with minimal initialization.</li>
</ol>
<p>But in case the users want to go configure the actor in detail, we are planning to provide a <code>Builder</code> approach and reduce boilerplate.</p>
<ol start="2">
<li>
<p>The <code>action</code> here that I have not initialized yet (because it's design isn't final) is how the actor will handle incoming messages. So we initialize the client with the initial state and the action. I will show their signatures and implementations in a minute.</p>
</li>
<li>
<p>Creating a message creates a one-shot channel and returns a <code>Tracker</code> for the actor's response. <code>client</code> sends the message, the <code>Actor</code> processes it and we are quite good. Note that this piece of code doesn't allow us to send closures and manipulate state yet. WIP!</p>
</li>
</ol>
<p>the code for client:</p>
<pre><code class="language-rust">pub struct Client&lt;M&gt; {
    handle: mpsc::UnboundedSender&lt;M&gt;,
}

impl&lt;M&gt; Client&lt;M&gt; {
    pub fn new&lt;A, S&gt;(state: S, action: A) -&gt; Self
    where
        M: Send + 'static,
        S: Send + 'static,
        A: Send + FnMut(&amp;mut S, M) -&gt; () + 'static,
    {
        let (handle, actor) = Actor::new(state, action);
        tokio::spawn(actor.run());
        Self { handle }
    }

    pub fn send(&amp;self, message: M) {
        let _ = self.handle.send(message);
    }
}</code></pre>
<p>actor:</p>
<pre><code class="language-rust">use tokio::sync::mpsc;

pub struct Actor&lt;T, A, M&gt; {
    state: T,
    receiver: mpsc::UnboundedReceiver&lt;M&gt;,
    action: A,
}

impl&lt;T, A, M&gt; Actor&lt;T, A, M&gt;
where
    A: Send + FnMut(&amp;mut T, M) -&gt; (),
{
    pub fn new(state: T, action: A) -&gt; (mpsc::UnboundedSender&lt;M&gt;, Self) {
        let (sender, receiver) = mpsc::unbounded_channel();
        (
            sender,
            Self {
                state,
                receiver,
                action,
            },
        )
    }

    pub async fn run(mut self) {
        while let Some(message) = self.receiver.recv().await {
            (self.action)(&amp;mut self.state, message);
        }
    }
}</code></pre>
<p>message:</p>
<pre><code class="language-rust">pub struct Message&lt;T&gt; {
    pub data: T,
    pub sender: oneshot::Sender&lt;T&gt;,
}

impl Message&lt;i32&gt; {
    pub fn create(data: &amp;i32) -&gt; (Tracker&lt;i32&gt;, Self) {
        let (sender, receiver) = oneshot::channel();
        let message = Self {
            data: *data,
            sender,
        };
        let tracker = Tracker::new(receiver);
        (tracker, message)
    }
}</code></pre>
<p>and tracker:</p>
<pre><code class="language-rust">pub struct Tracker&lt;T&gt; {
    receiver: oneshot::Receiver&lt;T&gt;,
}

impl&lt;T&gt; Tracker&lt;T&gt; {
    pub fn new(receiver: oneshot::Receiver&lt;T&gt;) -&gt; Self {
        Self { receiver }
    }
}

impl&lt;T&gt; Future for Tracker&lt;T&gt; {
    type Output = Result&lt;T, oneshot::error::RecvError&gt;;

    fn poll(self: Pin&lt;&amp;mut Self&gt;, cx: &amp;mut Context&lt;'_&gt;) -&gt; Poll&lt;Self::Output&gt; {
        let this = self.get_mut();
        match Pin::new(&amp;mut this.receiver).poll(cx) {
            Poll::Ready(Ok(v)) =&gt; Poll::Ready(Ok(v)),
            Poll::Ready(Err(e)) =&gt; Poll::Ready(Err(e)),
            Poll::Pending =&gt; Poll::Pending,
        }
    }
}</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="implementing-an-input-toolbar-in-flutter"><a class="header" href="#implementing-an-input-toolbar-in-flutter">Implementing an Input Toolbar in Flutter</a></h1>
<p>This post is about implementing an input toolbar to add images to a post, just like how it works in Twitter, Whatsapp, or other apps. I'm writing this quick post for one of my teammates at Upcarta. I will be brief and won't go into many details.</p>
<p>Here is our view. We wrap the view itself and the input toolbar with a <code>Column</code>.</p>
<pre><code class="language-dart">return Scaffold(
      appBar: AppBar(
        title: Text('Ticket #${ticket.ticketId}'),
        actions: [
          _CloseTicketButton(ticket),
        ],
      ),
      body: Column(
        children: &lt;Widget&gt;[
          _View(ticket: ticket).expand(),
          // The input toolbar and button
          _TextingKeyboard(ticket: ticket),
        ],
      ),
    );
</code></pre>
<p>Here is what the input toolbar looks like. I've omitted a lot of it for the sake of simplicity. You should adjust the paddings, etc. for yourself. One difficulty I had was adjusting the paddings and the sizes of the input toolbar widgets. One good option could be turning this whole view into a reusable compontent.</p>
<p>Note that I use my own widget extensions instead of <code>Padding</code>, <code>Flexible</code> and <code>Expanded</code> widgets. I think they keep the widget tree cleaner. But they are nothing special.</p>
<pre><code class="language-dart">  @override
  Widget build(BuildContext context) {
    return SafeArea(
      minimum: const EdgeInsets.only(
        bottom: kVerticalPaddingSmall,
        left: kHorizontalPaddingSmall,
        right: kHorizontalPaddingSmall,
      ),
      child: Row(
        crossAxisAlignment: CrossAxisAlignment.end,
        children: &lt;Widget&gt;[
          ConstrainedBox(
            constraints: const BoxConstraints(
              minHeight: 36,
            ),
            child: TextField(...),
          ).flex(),
          const SizedBox(width: 4),
          // Button
          SizedBox.square(
            dimension: 36,
            child: IconButton.filled(
              padding: const EdgeInsets.all(kVerticalPaddingSmall),
              onPressed: () {...},
              icon: const Icon(
                Icons.send,
                size: 20,
                color: AppColors.white,
              ),
            ),
          ),
        ],
      ).padding(top: kVerticalPaddingSmall),
    ).backgroundColor(AppColors.red[3]!);
  }
</code></pre>
<p>We are not done yet. The <code>_View</code>, which is the widget that actually shows the view itself should be wrapped into a <code>SingleChildScrollView</code> or some other scrollable. This is necessary because we want to have the keyboard take up space in the screen, limiting the size of the view, and turning it into a scrollable widget where it sits. Here is what I went with:</p>
<pre><code class="language-dart">return SingleChildScrollView(
      padding: const EdgeInsets.only(bottom: 56),
      keyboardDismissBehavior: ScrollViewKeyboardDismissBehavior.onDrag,
      child: Column(
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="job-application-questions-i-liked"><a class="header" href="#job-application-questions-i-liked">Job application questions I liked</a></h1>
<p>Here, I will compile application questions I liked answering.</p>
<p>I will write my answers in quote blocks, followed by my comments on the questions.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="bluecode"><a class="header" href="#bluecode">Bluecode</a></h1>
<h2 id="favorite-languages-and-tools"><a class="header" href="#favorite-languages-and-tools">Favorite Languages And Tools</a></h2>
<p>Which are your favorite languages and tools for building things? Please explain your experience and why you like them.</p>
<blockquote>
<p>The most important thing is that I should enjoy using a language or tool. Spending time with code all day, what I am doing should be a pleasure (at least most of the time). Simplicity is a big plus for this. Also, I shouldn't feel like I am hitting a wall with what I want to do (at least not very often). And my favorites so far would be Go, Flutter and Flair.</p>
<p>I learned Go for my internship at the University of Kent. The purpose of that project was to collect DDoS related-data about the most popular domains on the web on a daily or weekly basis. I was responsible for developing a tool that collects DNS and status data a given list of domains. Performance-wise, Rust or Elixir could make more sense, but Go made the development much quicker for a student. I got a lot of work done and had a good time. It's one of those languages with a big agenda, and I love that the agenda is simplicity. I really like the error handling and concurrency mechanisms of Go.</p>
<p>Most of my programming experience has been with Flutter and Dart to develop the mobile app of Upcarta. Even though I won't follow a career in mobile development (I want to do a little bit more exciting things), I enjoy coding with Flutter. Dart and Flutter's design is very good. I find it much easier to read compared to HTML, and the UI code rarely requires comments. Flutter is still young and there are gaps in the development ecosystem which make things frustrating for no obvious reason. But still it is a pleasure to code, and there are many useful packages built by the community that ease my pain.</p>
<p>Flair (https://github.com/flairNLP/flair) is an open-source NLP framework. I worked with NLP for my graduation project, and at first wanted to use huggingface and TensorFlow, its API and models. There was lots of boilerplate code and frustration about things not working. The NLP-guy at Upcarta recommended flair, which made things much faster. You can just use and fine tune state-of-the-art models with it. It is built on PyTorch, therefore is integrated well and can handle many different types of tasks such as sentiment detection, NER, etc. I recommend it to any friend who has an NLP project.</p>
</blockquote>
<h2 id="code-quality"><a class="header" href="#code-quality">Code Quality</a></h2>
<p>What for you is the most important for writing quality code?</p>
<blockquote>
<p>Coding is a very communicative process. You rarely code alone, and even if you code alone, a couple of months is enough for a piece of code to be mistaken for a stranger's. So quality code for me would be understandable and (obviously) performative code.</p>
<p>In order to make code understandable, it is important to determine the simplest blocks and combine them in a clear and intuitive way. The code should make sense and come as natural to the reader. There are many practices available for that such as variable naming, DRY and KISS. But in the end, I think it just comes down to understanding this approach. I have written and read a lot of low quality code in the past year, and I have rewritten a lot of it. Sometimes after writing some code, I just need to take my time and come back to it the next day.</p>
</blockquote>
<h2 id="favorite-code"><a class="header" href="#favorite-code">Favorite Code</a></h2>
<p>Which are your favorite open-source projects and packages?</p>
<blockquote>
<p>Bloc library and Nostr.</p>
<p>Bloc is a state management library built by the Flutter community. For a beginner, it was quite difficult to learn and use. But  once you learn, it is very easy to see why and how are the state changes are happening. It gives you clear, extensive control over the state.</p>
<p>Nostr is a protocol for anti-censorship, software-independent, decentralized social network. Basically it is just posting notes over relays, with cryptographic verification. I like it because it is very straightforward and opinionated about censorship. It also allows you to use whichever client you want, giving you the option to not use clients that will show you ads or features you don't like. Also, it is well integrated with the bitcoin environment (most of its users are bitcoin people-though I am not) so offers a unique way of monetization for the platforms and users with the feature of zapping posts and profiles. There is an active community that is building all sorts of things on top of Nostr. I hope the future of the social internet will not be at the hands of a couple of companies, and I believe Nostr could be the way.
Note: Technically, its uses are not limited to social media, but what I have seen the most is social media apps being built on top of it. I use Damus, a mobile social media app built on top of Nostr.</p>
</blockquote>
<h2 id="role-models"><a class="header" href="#role-models">Role-Models</a></h2>
<p>Do you have any programming role-models? Do you have any favorite book(s) on software? Who, which ones, and why?</p>
<blockquote>
<p>Jonathan Blow has been a role-model since I played the Witness and Braid at the age of 16. I also try to watch his talks on our need on a modern programming language to replace C and C++, and how some attempts got some things right and some things wrong. Currently he is building a new language called Jai. I admire his approach to programming concepts. Even though he has some sort of a bad reputation with the way he disagrees with people, I think he is a brilliant mind worth following.</p>
<p>So far no book on software has intrigued me that much.</p>
</blockquote>
<p>After this question, I picked up <a href="https://www.upcarta.com/resources/1006-the-mythical-man-month-essays-on-software-engineering">The Mythical Man-Month</a>, and it's delightful. Clear pieces on software development. I recommend the first parts where Brooks talk about the joys and woes of software.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="wingback"><a class="header" href="#wingback">Wingback</a></h1>
<h2 id="can-you-name-three-software-companies-you-admire-and-why-you-admire-them--or--which-technological-feats-of-the-past-inspire-you"><a class="header" href="#can-you-name-three-software-companies-you-admire-and-why-you-admire-them--or--which-technological-feats-of-the-past-inspire-you">Can you name three software companies you admire and why you admire them? -or- Which technological feats of the past inspire you?</a></h2>
<blockquote>
<p>Thekla Inc, Notion, Discord</p>
<p>Thekla is the video game company that made The Witness and Braid, which had profound impact on me. They are driven by the unique vision of Jonathan Blow, game developer and the inventor of the programming language Jai. Also, I like a lot that their current projects are secret. I'm waiting to be surprised.</p>
<p>Notion's product driven ambition deserves respect. At Upcarta, we try to be inspired by that. I also love how Notion can be useful from individuals keeping simple notes to companies organizing their workflows. We use Notion at Upcarta.</p>
<p>I love how organic Discord came to be, or at least how organic it seemed. It's "just what we needed". It was needed for gamers. I remember using skype to play games with my friends, and how painful that was. Switching to discord was fast and refreshing. But now it is great for working remotely, hanging out with your friends who live far away.</p>
</blockquote>
<h2 id="why-did-you-get-into-programming"><a class="header" href="#why-did-you-get-into-programming">Why did you get into programming?</a></h2>
<blockquote>
<p>I was studying computer science because I was academically successful and wasn't interested in anything else. I knew a bit of C++ from my curiosity, but I had no special interest for programming until the third year of university. The first year courses (Intro to Programming, Advanced programming, etc) were just a part of school, the homeworks felt like puzzles.</p>
<p>What I would consider got me into programming was two things: the Programming Languages course I took and the following internship at Kent. There, I learnt Go and I discovered how excited I got to discover new ways of programming. Since then I did a little bit of Elixir and Go, and now I am learning Rust. The joy of programming only increases day by day.</p>
</blockquote>
<div style="break-before: page; page-break-before: always;"></div><p>Here is a small snippet I used today to send some files using curl. I usually use Postman to test my API, but it failed miserably to send a couple of files. Here is what I did using curl.</p>
<pre><code class="language-sh">curl \
-X POST -H "Accept: application/json" \
-F 'attachments[]=@Chest.pdf' \
-F 'attachments[]=@Core.pdf' \
-F 'body=hello world' \
myapi.test/api/endpoint
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><p>Here is the chain of commands I used to reduce the size of a video on my mac. I asked claude, so maybe there is room for improvement. It's funny how you can't do this with the export options of macos.</p>
<p>get video info:</p>
<pre><code>ffprobe "video.mov"
</code></pre>
<p>get video original size:</p>
<pre><code>ls -lh "video.mov"
</code></pre>
<p>compress:</p>
<pre><code>ffmpeg -i "video.mov" -vf "scale=1280:720" -r 30 -c:v libx264 -crf 28 -c:a aac -b:a 96k "video_compressed.mov"
</code></pre>
<p>breakdown of the parameters:</p>
<pre><code>-i: Input file
-vf "scale=1280:720": Resize to 720p
-r 30: Reduce frame rate to 30fps
-c:v libx264: Use H.264 video codec
-crf 28: Constant Rate Factor 28 (range is 0-51, lower is better quality, 18-28 is usually good)
-c:a aac: Use AAC audio codec
-b:a 96k: Audio bitrate 96kbps
</code></pre>
<p>How it could be better:</p>
<ol>
<li>For screencasts with text, we could use a lower CRF (maybe 23-25) and try these additional options:</li>
</ol>
<pre><code>ffmpeg -i input.mov -vf "scale=1280:720" -r 30 -c:v libx264 -crf 23 -preset slower -tune stillimage -c:a aac -b:a 96k output.mov
</code></pre>
<p>breakdown:</p>
<pre><code>-preset slower: Better compression at the cost of encoding time
-tune stillimage: Optimized for screencast-type content
</code></pre>
<ol start="2">
<li>Or if you want to maintain even better text quality while still getting good compression:</li>
</ol>
<pre><code>ffmpeg -i input.mov -vf "scale=1280:720" -r 30 -c:v libx264 -crf 20 -preset veryslow -tune stillimage -profile:v high -c:a aac -b:a 96k output.mov
</code></pre>
<p>This would produce a larger file (probably 3-5MB) but with noticeably better text quality.</p>
<p>The reason my original command produced such a small file (912KB) with still-readable quality is that H.264 is particularly good at compressing screen recordings, especially when there's limited motion. The macOS export feature uses more generic settings that don't take advantage of these optimization opportunities.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="term-paper-on-open-source-software-and-the-triple-helix-model-of-science"><a class="header" href="#term-paper-on-open-source-software-and-the-triple-helix-model-of-science">Term paper on Open-source Software and the Triple Helix Model of Science</a></h1>
<blockquote>
<p>This is a term paper I wrote for the Science and Society course at Sabanci University in the spring of 2022.</p>
</blockquote>
<p><strong>Term Paper Question:</strong> What is free and open-source software? Where does it stand in the Triple Helix Model of the social organization of science? Does it have remedies for the disadvantages of the Triple Helix Model? Does it have its weaknesses with respect to the Triple Helix Model?</p>
<h2 id="introduction"><a class="header" href="#introduction">Introduction</a></h2>
<p>The social organization of science underwent considerable change during the 1980s, from the Liberal Model which gave universities the freedom to choose how to allocate the resources they are granted by the government, to the Triple Helix Model in which the scientists also collaborated heavily with corporations to conduct research. This change had many significant consequences on the relationship between the science community, private sector, government, also public. As it will be shown in the following, section, the Triple Helix Model has some fundamental problems relating to the well-functioning of the community of science as the producer of reliable knowledge. There is considerable work on how to achieve well-ordered science through theoretical and practical frameworks that aim to organize the relationship between the aforementioned actors. But one mode of production in the field of computer science, namely Free and Open-Source Software can be examined to shed light on the research on well-organized science. In this approach, certain mechanisms that stem from the community of computer science (which consists of computer scientists and end-users) regulate the relationship between corporations, the government, and the community of computer science. The second section briefly explains the Triple Helix Model, its history, as well as its problematic aspects. The third section explains Free and Open-Source Software, its history, and its mechanisms. In the fourth section, the interaction between Free and Open-Source and the Triple Helix Model is examined, and the solutions that Open-Source brings are discussed. In the last section, the shortcomings of Open-Source are brought up, and a conclusion is provided.</p>
<h2 id="what-is-the-triple-helix-model-of-science-thm"><a class="header" href="#what-is-the-triple-helix-model-of-science-thm">What is the Triple Helix Model of Science (THM)?</a></h2>
<h3 id="21-the-liberal-model"><a class="header" href="#21-the-liberal-model">2.1 The Liberal Model</a></h3>
<p>In order to understand the Triple Helix Model, we first need to briefly explain the Liberal Model that precedes it. In the Liberal Model, the main source of grants and patents are the state. Both the science community (mostly research centers and universities) and corporations seek grants for the research and the resulting patents belong to the state. Even though the Liberal Model has its weaknesses, it allows the universities to allocate the resources given by the government freely, meaning that even if scientists wish to do research on very niche fields, they can follow their own desires. This also allows the conduction of basic science, which does not necessarily have immediate benefits to the society or the conduction of science itself but has proven that it has invaluable uses in the long term, and nuclear energy is a major example. Also, since the scientists did not have any extra benefits from their research except for the prestige and recognition, they could stay disinterested and conduct their research honestly, at least to a certain degree.</p>
<h3 id="22-the-triple-helix-model"><a class="header" href="#22-the-triple-helix-model">2.2 The Triple Helix Model</a></h3>
<p>After the 1980s, the social structure of science changed dramatically, resulting in the Triple Helix Model. In this model, funding of research is predominantly done by corporations as Research and Development (R&amp;D) projects. Governments also fund R&amp;D, but an overwhelming proportion of R&amp;D funding comes from the private sector (Irzık, 2022). Intellectual property rights are much more aggressive as companies aim to get the patents or shared ownership of patents of the research they fund and prevent the disclosure of certain processes such as data collection, how data was handled, the patent details, and the methods of reproduction. This means that scientific knowledge is commodified, belonging to companies that fund its production. Also, industry and universities have novel ways of working together. One well-known example of this is the technology parks at university campuses, in which researchers use both university and private sector resources. Since it was less costly, companies outsource universities instead of having their own independent laboratories. On the other hand, scientists have a channel of possible gains: money. Therefore, they try to get contracts and collaborate with companies to continue their research, and sometimes abide by the rules of the private sector. As a result, universities are becoming entrepreneurial and profit-driven, and the control of what research would be funded shifts to the trends of the market and what is profitable. These characterize the Triple Helix Model, in which the state, the industry, and the scientific community collaborate in various combinations.</p>
<p>The triple helix model creates vulnerabilities in the community of science by undermining the values and norms of science to produce reliable knowledge, also known as the Mertonian norms. These norms are universalism, communalism, disinterestedness, and organized skepticism (Merton &amp; Storer, 1998). They are valuable for the well-functioning of science within the scientific community. Through non-disclosure agreements, THM creates gaps between the research done by a scientist and the community, not allowing free interaction, sharing, and criticism of ideas/research, undermining the norm of communalism. Also, THM provides scientists an additional motivation for financial gain which undermines the disinterestedness principle of the scientific community. The profit-driven market damages the production of reliable knowledge, which is the ultimate goal of science. Another problem created by THM is that bias is introduced to research (Sismondo, 2008) which inhibits organized skepticism and disinterestedness.</p>
<h2 id="what-is-free-and-open-source-software-foss"><a class="header" href="#what-is-free-and-open-source-software-foss">What is Free and Open-Source Software (FOSS)?</a></h2>
<p>To explain Free and Open-Source Software (FOSS), first, it is important to note that what is at hand is the open-source mode of production, not the open-source social movement, even though the two are closely related. In the sense of the mode of production, FOSS is about the organization of the community of computer scientists, the private sector, and members of the public who use the products of the private sector. The idea of open-source software is software with the source code accessible by everyone so that it can be inspected, modified, and improved by anyone. Anyone can create a copy of the code, modify it, and put it next to the code they took, so the community can decide which is better. And the modified code can be sold as well, under certain mechanisms of the FOSS. At the first glance, the idea might seem to undermine competition and kill creativity as well as the motivation for working on something new, but that is not the case. As it will be shown, open-source has fostered a competitive environment for computer scientists, corporations, and end-product users, manifesting and embodying parallel characteristics with the values of science.</p>
<p>In this section, open-source software will be examined with its history, successes, and mechanisms, following the work of Boldrin and Levine (2010).</p>
<p>Many of the great inventions that are still in use occurred (or have influenced cutting-edge technology that we use today) when software was not even patentable, such as the compilers, assemblers, graphical user interfaces (GUIs), linked lists, object-oriented programs, databases, search algorithms, font displays, word processing, and computer languages. These happened before 1981, when the Supreme Court decision in Diamond v. Diehr, changed the tradition of unpatentable software. And even after when it could and would be copyrighted, the copyright would not be respected as it is in the other fields of science. One reason for this was the customers: users would use programs in different systems, or share with one another, violating license agreements. It is true that copyright reduced copying software, but eventually, did not completely prevent it.</p>
<p>Free and open-source software has shown that innovation is not a result of copyrights and intellectual monopoly. The relationship is the very opposite. Only after a dynamic period of creativity, success, and innovation, do copyrights come into play. Once, pioneers of technology and research, who now have run out of exciting ideas, need government protection against their new competitors with creative ideas to drive the engine of success. Fresh ideas are blocked by the “old ways”, not for the promotion of creativity and innovation but for the protection of profit. The software industry, by relinquishing copyrights and patentable software voluntarily, created an innovative and competitive environment. Instead of copyright, they release the software under a “copyleft” license, which forces the sellers of copylefted software also allow the software to be copied by the competitors. This voluntary agreement protects free competition from intellectual monopoly. The motivation is not only about the values of FOSS, but there are also many cases in which only being able to enter the market is very profitable and a monopoly in the market is not worth seeking. Well-known and worth mentioning examples of open-source software would be Linux, which is one of the three major operating systems, that is also used by Mac OS and Google, and many major database management systems (DBMS) MySQL, PostgreSQL, MariaDB, the scripting language PHP, and many popular programming languages, with the examples of Python and Ruby. As it can be seen, open-source software has been a huge success.</p>
<p>The aforementioned free software license is known as the GNU General Public License, allowing software source code to be made public and sold with the condition of the modified code to be under the same license. Free, accessible software allows the contribution of many parties, and also makes their contribution freely available, promising the users of the software access to the source code as well. Programmers from around the world collaborate in a loosely organized way, forming teams or individually working, contributing themselves and benefiting from each other’s contributions. This is an incentive for both the contributing and benefiting sides, as any contribution can lead to a team of programmers competing and collaborating with others, in the end, helping them develop their software even further.</p>
<p>And finally, how open-source software does not undermine profitability can be explained by a concrete example. Linux, as mentioned before is an open-source operating system. Its source code can be accessed and modified by anyone. Red Hat customized the Linux system it accessed for free by developing many useful features, and later on putting its package on the market for $59.95. And as explained before, the Red Hat package is also open-source, thus accessible by others. Two other companies, HCI Design, and Linux Emporium attempted to sell the Red Hat package at much cheaper prices of around $16. But even though their prices were much more affordable, they could not sell as much and had to redraw from the Linux market, and Red Hat kept its place. The reason is the prestige of Red Hat as a company and the trust people put in them, as well as the technical support that can be provided the best by Red Hat since they wrote the code. Red Hat is still one of the industry leaders with many offices worldwide.</p>
<h2 id="how-does-foss-interact-with-thm"><a class="header" href="#how-does-foss-interact-with-thm">How does FOSS interact with THM?</a></h2>
<p>The triple helix model of the social organization of science has certain weaknesses and problems as briefly explained in Section 2. FOSS addresses some of these problems in a way that can be applied to the other fields of sciences as well. First, it is very compatible with the norms and values of science in a bold way, and second, it interacts with the private industry and actually manages to put pressure on the industry in a successful way. The following subsections are about how FOSS manages these.</p>
<h3 id="41-coexistence-of-the-norms-of-science-and-private-industry"><a class="header" href="#41-coexistence-of-the-norms-of-science-and-private-industry">4.1 Coexistence of the norms of science and private industry</a></h3>
<p>Free and open-source partly incorporates Mertonian norms in its values. Even though there is no active mechanism against discrimination in FOSS (this is not what FOSS is concerned with), any programmer can contribute to ongoing research and implementations, and share their ideas within the community. What matters is the contribution. This is in line with the universalism norm.</p>
<p>Communalism is very important for FOSS. It is one of its core values, allowing the whole community of researchers and programmers to freely share their ideas and innovations, as well as benefit from others’ work. Progress and intra-community flow of ideas and resources are not hindered by the motivation of profit. FOSS is so valuable for creativity and competition that even the largest companies in the industry have open-source departments, they host open-source contests, projects, or events that programmers from all around the world can join. Profit is not an enemy of progress.</p>
<p>Researchers or programmers might have personal gains from their work, but this does not hurt the disinterestedness norm, because the code is easily accessible and open to scrutiny by others. If their work has certain shortcomings due to their personal interests, members of the community will use the source code to do it better. This is one of the most important advantages of open source.</p>
<p>Since the code is accessible and modifiable by all; correction, optimization, and improvement are swift. Members of the FOSS community collaborate with scrutiny and aim to achieve the best of their potential through competition. Private industry often takes advantage of this and rewards the individuals who find bugs or inefficiency in their code. Therefore, FOSS also incorporates the norm of organized skepticism.</p>
<h3 id="42-community-vs-corporation--open-source-vs-intellectual-monopoly"><a class="header" href="#42-community-vs-corporation--open-source-vs-intellectual-monopoly">4.2 Community vs. corporation – Open Source vs. Intellectual Monopoly</a></h3>
<p>The market competition and the commodification of knowledge create certain problems for science. Since the industry funds most of the research and holds the patents, it has a serious amount of control over the results of research. Non-disclosure agreements or patents prevent the rest of the industry or researchers to benefit from successful research or question it. The mechanisms of FOSS can be a valuable asset against the power the market holds over the scientific community. The code being open-source sure is very effective, but also pressures the industry to stay close to open-source. A remarkable example of this is MariaDB and MySQL. MySQL is a database management system, created by Michael Widenius and his cofounders and released in 1995 under free software license. It is important to note that the founders chose to release it open source because “they have been using free software for 10+ years and wanted to give something back” and also it “did not hurt their income”. MySQL was first bought by Sun in 2008, and in 2009 Oracle started to acquire Sun. This meant that the original founders did not have control over the copyright management of MySQL from then on. Hence Widenius decided to work on the current version of MySQL independently, gathering a team of software developers (that also include the founders of MySQL) who would want to contribute to an open-source version of MySQL, which was named MariaDB (Widenius, 2017). Because MariaDB will “always be open source”, and open source has many advantages for the users, it creates strong competition for Oracle. Since then, Oracle has not changed its copyright for MySQL, and MySQL stays open source as well. Thanks to the endeavors of Widenius and the community, MySQL and MariaDB are two competitive open-source software that is still in use today. This historical example demonstrates how open source can be of use against the industry and the intellectual property rights which hinder better research, better end products, and creativity.</p>
<h3 id="43-what-are-some-weaknesses-or-shortcomings-of-foss-with-respect-to-thm"><a class="header" href="#43-what-are-some-weaknesses-or-shortcomings-of-foss-with-respect-to-thm">4.3 What are some weaknesses or shortcomings of FOSS with respect to THM?</a></h3>
<p>One of the problems created by THM is that scientists cannot commit to basic/pure research as they wish, because finding funds is much more difficult compared to industry-focused applied research. The material incentives or support are insufficient because there is no immediate gain from pure science. Free and open-source software is not a remedy to this problem for now, but the relationship between science and the industry, and how it could be organized by using the values of free and open-source software is open to further examination.</p>
<p>Also, even though FOSS has shown a path that can be followed and emphasized more, a lot of the code that is written today is still not open source, and corporations keep their profit-driven approach in the same way with their R&amp;D projects, and the tension between the helixes of the model remains.</p>
<h2 id="conclusion"><a class="header" href="#conclusion">Conclusion</a></h2>
<p>Free and open-source software has managed to deal with serious threats from the industry through fostering creativity and innovation as well as maintaining competition and collaboration at the same time. There is a lot to learn from the values and practices of FOSS for science to function well in THM. Science can resist the private industry the same way open-source does by using similar tools, creating an Open Science/Research that can put pressure over the industry using the “copyleft” approach, having its own competitive mechanisms and pulling the industry closer to itself. The discussion of free and open-source software and science is open to further questions and contributions.</p>
<h2 id="references"><a class="header" href="#references">References</a></h2>
<ul>
<li>Boldrin, M., &amp; Levine, D. K. (2010). Chapter 2: Creation under Competition. In Against intellectual monopoly (pp. 15–22). essay, Cambridge University Press.</li>
<li>Irzık, G. 2022, Changing Social Organization of Science and its Impact on Research and Universities, PHIL 450 – Science and Society lecture slides.</li>
<li>Merton, R. K., &amp; Storer, N. W. (1998). The Normative Structure of Science . In The Sociology of Science: Theoretical and Empirical Investigations (pp. 267–278). essay, University of Chicago Press.</li>
<li>Sismondo, S. (2008). Pharmaceutical company funding and its consequences: A qualitative systematic review. Contemporary Clinical Trials, 29(2), 109–113. https://doi.org/10.1016/j.cct.2007.08.001</li>
<li>Widenius, M. (2017, February 17). MySQL-MariaDB History talk. [MariaDB website]. https://mariadb.org/wp-content/uploads/2019/11/MySQL-MariaDB-story.pdf</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="does-the-shift-from-behavioral-ai-to-deep-learning-constitute-a-kuhnian-paradigm-shift"><a class="header" href="#does-the-shift-from-behavioral-ai-to-deep-learning-constitute-a-kuhnian-paradigm-shift">Does the Shift from Behavioral AI to Deep Learning Constitute a Kuhnian Paradigm Shift?</a></h1>
<blockquote>
<p>This is a paper I wrote for the <strong>Science and Society</strong> course at Sabanci University in the fall term of 2021.</p>
</blockquote>
<p><strong>Abstract:</strong> Thomas Kuhn brought about a new account of science, seeking to capture its socio-historical character, and coining the (initially not very well defined) term paradigm to discussions of philosophy of science. Since then, philosophers attempted to reconstruct the history of numerous scientific disciplines with Kuhn’s philosophical account of science to understand the developmental history of science better.</p>
<p>Artificial intelligence is a subfield of computer science that aims to build systems that have the intelligence properties of a human. Human intelligence is a very complex concept, a mystery not solved yet, and there is no consensus on how to achieve human intelligence in machines. There are several approaches to AI that characterized AI research in different periods, and this paper will focus on behavioral AI and deep learning. And this paper aims to determine whether the shift from behavioral AI to deep learning constitutes a Kuhnian paradigm shift and whether Kuhn’s account of science is compatible with the research patterns of these fields.</p>
<h2 id="introduction-1"><a class="header" href="#introduction-1">Introduction</a></h2>
<p>In "The Structure of Scientific Revolutions", Thomas Kuhn put forward a socio-historical account of science that aims to capture ways of doing science during certain scientific periods marked by some central theories<sup class="footnote-reference" id="fr-note-1"><a href="#footnote-note">1</a></sup>. He named these distinct periods of science as paradigms and explained science as a community activity under a paradigm, bringing wide discussions to the philosophy of science. Many philosophers and scientists tried to understand the development of their disciplines by applying Kuhn’s account of science. Numerous works examine natural sciences, social sciences, and more with the Kuhnian perspective.</p>
<p>As a comparably younger research discipline, Computer science and its fields of study, using existing or novel research methods seem to be a completely new research area for philosophers of science to work on. Artificial intelligence (AI) focuses on building “intelligent” systems that can act without being explicitly coded. There have been different approaches to AI, characterizing and driving certain periods of research. This paper will focus on behavioral AI, which makes use of certain techniques that lead to the emergence of intelligent properties, and deep learning, which uses data to train agents in a statistical way to achieve artificial intelligence.</p>
<p>This research paper aims to discuss how much of the shift from behavioral AI to deep learning can be captured by Kuhn’s developmental account of science. More specifically, to find out whether the shift from the earlier science of AI to deep learning constitutes a Kuhnian paradigm shift. A Kuhnian examination of deep learning can be valuable to shed better light on the history and science of artificial intelligence.</p>
<p>The paper is structured in the following way: First, Kuhnian account of science will be explained briefly. That will be followed by a summary of the history of AI research, with a focus on behavioral AI and deep learning. Finally, a discussion of whether this period of the history of AI can be reconstructed with the Kuhnian account of science will take place.</p>
<h2 id="kuhns-account-of-science"><a class="header" href="#kuhns-account-of-science">Kuhn’s Account of Science</a></h2>
<p>The term paradigm, coined by Kuhn to the philosophy of science is a complicated term loaded with different meanings that brought many discussions because of the lack of a concrete and single definition. Shortly, a paradigm can be explained as the totality of the scientific understanding and methods of a certain period of scientific activity, widely accepted by the scientific community.</p>
<p>An example of a paradigm can be Newtonian physics. It has well-formulated three fundamental laws and guided the scientific community for a long time until the shift to quantum physics, another paradigm of physics, occurred. Newtonian physics could explain a broad range of phenomena such as the movement of planets, objects that we can see and interact with it, but failed to explain the physics of small particles or what happens at the speed of light. It was very influential for a long time and was taught in textbooks, which are used to bring up new generations of scientists.</p>
<p>According to Kuhn, the development of the scientific process is not linear and accumulative as described in textbooks. The scientific community of a paradigm works under the paradigm, making use of the main theories of the paradigm and attempting to solve more and more puzzles with them. Kuhn names this process as normal science. During normal science, the scientists do not strive to try to falsify the paradigm’s theories at hand. On the opposite, when they cannot solve a particular problem, they tend to make ad hoc maneuvers and/or put it aside as an anomaly that will hopefully be sorted out in the future. The puzzle-solving processes of the community lead to many such anomalies and the paradigm resists these anomalies, it is not given up easily. When quantum physics was studied immensely, the researchers did not try to falsify it when they had unexpected results from their experiments. Rather, they tried to strengthen the new laws, make corrections, repeat experiments in different conditions to explain phenomena that were unanswered by Newtonian physics.</p>
<p>Some anomalies become more and more pressing, and at some point, turn into a crisis among the community. The future with the current paradigm does not look so bright, the community as a whole does not believe in its promises of success. At this point, a paradigm shift ̧ or a revolution might occur. If an opponent theory that is more promising for solving those anomalies emerges and it can more or less explain what was explained by the current paradigm so far, the community might face a choice between the two paradigms.</p>
<p>Kuhn suggests that the choice of a paradigm is not a direct one and cannot be explained rationally. One reason for this is the incommensurability of the two paradigms. Incommensurability is the impossibility of translating the meaning of the explanations under the paradigms. As a result, the two paradigms cannot be compared with each other concerning certain metrics. And there is no way of reconciling them. This choice is based on the beliefs and values of scientists. It is important to note that this also allows a rational disagreement in theory choice.</p>
<p>Furthermore, Kuhn maintains that even though the choice of paradigm for the scientific community does not have a rational method, it is not completely loose. A paradigm must be able to solve -at least most of- the problems solved by previous problems (preserve the problem- solving ability of the previous paradigm) and also be promising about solving future problems (resolve some outstanding and recognized problems in new ways). And this is how one might call progress occurs in science.</p>
<h2 id="history-of-ai"><a class="header" href="#history-of-ai">History of AI</a></h2>
<p>Artificial Intelligence is difficult to define because intelligence itself is difficult to define. Without going into that cumbersome region, we can briefly define AI as computer systems that can act without being hard-coded, for tasks that traditionally require human intelligence. It incorporates natural language processing (translation, recognition, and communication), decision-making, problem-solving, robotics, and more. It is a young research field, born with and within the field of computer science itself. Even though it took some time for AI to be recognized as a respected and mature field on its own, today it is more popular than ever and is applied to a wide range of problems.</p>
<h3 id="first-two-phases-of-the-science-of-ai"><a class="header" href="#first-two-phases-of-the-science-of-ai">First two phases of the science of AI</a></h3>
<h4 id="1-the-golden-age-of-ai"><a class="header" href="#1-the-golden-age-of-ai">1. The golden age of AI</a></h4>
<p>To be able to explain the shift from behavioral AI to deep learning, first, it is necessary to briefly mention what comes before. The field of AI was kickstarted by the famous work of Turing on theorizing the computer (Entscheidungsproblem-the existence of problems that cannot be answered by following a recipe, Turing was talking about undecidability).</p>
<p>The work of Turing and others who followed him paved the way for the invention of computers, and eventually created some new questions about human intelligence. Especially with the effect of media, computers were called “the electronic brain”, expectations got very high, and artificial intelligence was a new problem to solve. But it was important to answer the question of what intelligence was. An answer to that was “general intelligence”, which basically meant that a robot must perform activities, make decisions, and solve problems just like a human.</p>
<p>Turing came up with a -once more- famous theory on artificial intelligence this time. He proposed the Turing test, in which the robot aims to deceive a professional assessor as they chat through written media. The test was discussed widely and had significant effects on the field. More tasks followed the test:</p>
<ul>
<li>SHRDLU, a simulated computer that was put into a simulated environment with an initial configuration of blocks and was expected to change the configuration of the blocks in accordance with the commands it took. The robot was expected to be able to tell which objects there were, in what position; what actions to perform, and in which order it should perform its actions.</li>
<li>SHAKEY, a mobile robot put into a real-world environment and was expected to understand commands and break them into performable actions by itself. It combined logical reasoning and physical action.</li>
<li>Other problems of decision such as Towers of Hanoi. The robot is expected to perform a search among many states the environment or itself can be.</li>
</ul>
<p>The problems AI researchers decided to take on turned out to be NP-Complete problems. This means that they cannot be solved efficiently and easily, and the combinatorial explosion (especially with the technology of that day) was difficult to overcome.</p>
<h4 id="2-knowledge-based-systems"><a class="header" href="#2-knowledge-based-systems">2. Knowledge-based systems</a></h4>
<p>After the initial excitement and promises, the AI community fell into a plateau and could not progress. They could solve some problems, but the problem of search was hard and not feasible at that time. Therefore, the scientists had to take another path. And this was the knowledge-based systems. These systems were given information that they would use to solve narrow problems. These systems attempted to model the world using knowledge bases.</p>
<p>Logical reasoning with the use of information lead to another public excitement and public interest. Many experimental products were aimed to be delivered to public service:</p>
<ul>
<li>MYCIN was a project to have a database on bacterial infections and it was expected to diagnose the problem after asking questions to the physician. It used its encoded knowledge and an inference engine for this purpose.</li>
<li>CYC, a huge project to incorporate all human knowledge into a knowledge database and make the computer a reasoning machine with the knowledge it has. CYC was expected to symbolically understand the relationships between different knowledge, and infer conclusions based on those. The size of the database was hundreds of thousands of knowledge pieces. But it had many shortcomings such as not being self-evolving and the amount of data it required.</li>
</ul>
<p>Complex or simple, the approaches to building intelligent systems at these periods had certain shortcomings such as the necessity of being hard-coded, complexity barriers, the storage and computation requirements.</p>
<h3 id="behavioral-ai"><a class="header" href="#behavioral-ai">Behavioral AI</a></h3>
<h4 id="what-it-is-main-principles"><a class="header" href="#what-it-is-main-principles">What it is, main principles</a></h4>
<p>Robert Brooks from MIT was the leading scientist who refused the AI research principles done in that period. He worked on building intelligent systems that would operate in a physical environment, and his approach was focused on how the system would behave in certain situations. This mainly required identification of fundamental behaviors and the relationships between them and adding them to each other on certain principles of priority. This was called a subsumption architecture.</p>
<p>One key difference between behavioral AI and earlier research was the fundamental starting point of research: Intelligence and some of its properties such as reasoning and problem solving was not something to be coded, but rather emergent. The focus was on the interaction of the system with its environment based on its perception, and other aspects of intelligence would follow.</p>
<p>Behavioral AI also rejected the principle of a divide-and-conquer approach to intelligence where the components of intelligence such as learning, perception, and reasoning were divided and worked on separately. Behavioral AI claimed that these components were tied together, and it was important to understand their collaboration.</p>
<p>Another fundamental principle brought up by behavioral AI was based on what the behavioral AI community was heavily critical about previous work: The disconnectedness from the environment. Knowledge-based AI systems worked as a “perceive-reason-act” loop that ignored any change in the environment. In behavioral AI, the situation-behavior relationship was crucial. The agent would perceive its environment, recognize the changes in the environment and react to them.</p>
<p>Even though many researchers of behavioral AI wanted to leave logical reasoning behind, some were enthusiastic about merging the two approaches. With the usage of behavioral AI and logical reasoning, an agent-based view of AI was born. There were several principles:</p>
<ol>
<li>Reactiveness: The agent must arrange its behavior based on the variations in the environment.</li>
<li>Proactiveness: The agent must systematically work to reach its goal.</li>
<li>Socialness: The agent can be with other agents in an environment and must be able to
cooperate or compete with them.</li>
</ol>
<p>Behavioral AI also changed direction about how the decisions of the AI should be. Earlier AI work was based on creating AI that would behave and decide similarly to humans. There was a shift to making the best choice with the agent approach, which did not always mean the most humane choice. The concept of utility was introduced. Utility is a method to mathematically model the behavior of an agent, based on certain scores associated with the perceptions and actions of AI. The agents would be taught about preferences, and it would decide on those based on which option provides maximum expected utility. And many different behaviors could be achieved using utilities because it allowed being used with different preferences.</p>
<p>The agents were not completely naïve about their perceptions and inferences. They had certain beliefs about the state of the environment and made use of Bayesian Inference and statistical reasoning to improve their beliefs when certain changes in the environment occurred. Bayesian inference uses the information at hand and probabilistic methods to make better guesses. And for intelligent agents, usage of Bayesian methods improved decision making. Knowledge of the environment and perceptions at a certain point allows the agents to calculate certain probabilities of some events and make decisions accordingly.</p>
<h4 id="the-problems-it-could-solve"><a class="header" href="#the-problems-it-could-solve">The problems it could solve</a></h4>
<p>Behavioral AI was much faster than systems based on logical reasoning because it did not need rules and logical inferences which required computational power to handle. Also, behavioral AI was successful at building systems that were actually embodied in the real world.</p>
<p>HOMER was, similar to SHRDLU, a simulated robot, interacting with its environment based on given commands and changes in the environment. It could reason about time, changes that would happen, and react to unexpected changes. If it was told that it had an object, and then if it was told that the object was removed, it would be “surprised”. It could answer questions about the dates, some appointments it has and could talk about its plans about those.</p>
<p>In 1997, DeepBlue, an intelligent system that was made to play chess against Kasparov and could defeat the grandmaster with some upgrades after an initial defeat. Another great success of the behavioral approach was that efficient SAT solvers based on AI were developed and this meant that now there were better solutions for most NP-Complete problems.</p>
<h4 id="the-problems-it-couldnt-solve"><a class="header" href="#the-problems-it-couldnt-solve">The problems it couldn’t solve</a></h4>
<p>It did not scale well, because the decision-making processes of behavioral agents require the agent to consider perceptions and a history of perceptions it has and search for the best possible decision. Even though DeepBlue could play chess and defeat world champions, it was not able to deal with problems that got much more complex much faster, such as playing go. It would take another approach for AI researchers to do that task.</p>
<p>The agents were still required to be told what they were supposed to do. They did not learn or improve their behavior in time. This also meant that they could work on one task only. Applying them to another task requires a lot of effort. Still, they worked well in the attempted areas. The problems they could not solve related more to what the researchers attempted to or not. This is mostly due to the complexity of the problems. Behavioral AI researchers did not attack many problems today’s researchers are tackling today.</p>
<h3 id="deep-learning"><a class="header" href="#deep-learning">Deep Learning</a></h3>
<h4 id="history"><a class="header" href="#history">History</a></h4>
<p>Even though deep learning and the use of neural networks date back to the theories of Warren McCulloch and Walter Pitts in 1943, it took 32 years until the first multilayered network was developed by Kunihiko Fukushima. The development of deep learning boomed in the 2000s with the abundance of data and certain thresholds of success leading the field to become increasingly popular worldwide.</p>
<p>In 2014, DeepMind from the UK was bought by Google. DeepMind built systems that could play video games, eventually leading to the mediatic success of AlphaGo, the agent that defeated the world champion at Go. They used reinforcement learning techniques to build agents that would learn from scratch: there was no recipe given to the agent at all. The agent would only use the information of pixels in the learning phase and improve its performance with each trial.</p>
<p>AlphaGo was trained for months by playing against Go players. DeepMind went on working on a better version which they named AlphaGo Zero and trained it by only playing with itself. And it is noteworthy that training of AlphaGo Zero only took days. There being only three years between these two systems demonstrates the recent acceleration of the field.</p>
<h4 id="what-it-is-main-principles-1"><a class="header" href="#what-it-is-main-principles-1">What it is, main principles</a></h4>
<p>Deep learning is a machine learning technique. Machine learning is based on giving pre- processed data to a program as input and making it perform a task based on computations. The difference of machine learning from previous approaches to AI is that the system is not given any recipe on how to do the task, instead, it is trained with data based on an error correction procedure. This approach was never seen before as every approach until machine learning had to give certain rules to the system.</p>
<p>One of the main methods of training a machine learning model is supervised learning. In supervised learning, the machine is initially in a semi-random state, then it is fed with training data and trained based on how far its predictions are from the training data. Deep learning is a data-hungry method, and the quality of data is as important as the amount of data. Therefore, data pre-processing has an important role in the training of machine learning algorithms. Better preprocessing yields better results.</p>
<p>Deep learning, or an artificial neural network, is a technique inspired by the way biological neurons work. A neuron is the fundamental unit of the neural system. It receives an electrical signal from the previous one, and if the signal is strong enough, fires to stimulate the next neuron. Similarly, artificial neural networks consist of perceptrons. A perceptron takes a vector of numbers as input and has a weight vector in which every weight corresponds to a number in the input. These vectors are used in an activation function to decide if the perceptron should fire or not. The problem to be solved with deep learning is to find the appropriate weights for each neuron.</p>
<p><img src="posts/philosophy/../../images/nn.png" alt="The Rust Logo" />
<em>Figure 1: A neural network architecture<sup class="footnote-reference" id="fr-note2-1"><a href="#footnote-note2">2</a></sup></em></p>
<p>In neural networks, the perceptrons are used in layers, and there are many layers in an ANN architecture. This technique is called Multilayer Perceptrons. Each layer of neurons is connected to the previous and next layer, and every neuron takes every output from the previous layer. With each input, layers take and process the input, and neurons are fired or not depending on the input and current weights. The information at each layer is feedforwarded into the next layer until the end and there is an output of the whole system. This output is compared to the desired output of the training instance, the error is backpropagated in the layers with the reverse order, and weights of perceptrons are tweaked. The backpropagation technique is how the weights of a neural network are adjusted.</p>
<p>The reason that deep learning is called that way is mostly that it has many layers of neurons. This allows levels of abstraction as each layer, meaning that every layer can learn and process more and more complex relationships in the data. It also means that the network has more neurons, and these neurons have more connections between them. Different techniques of deep learning provide varying connection types to achieve different goals (Recurrent Neural Networks and Convolutional Neural Networks are two examples).</p>
<p>The success of deep learning is based on its mathematics, as demonstrated by Hornik et al. A multilayered neural network can approximate any real-valued function if it is trained appropriately<sup class="footnote-reference" id="fr-note3-1"><a href="#footnote-note3">3</a></sup>. They are successful at generalization, inference, and detecting hidden patterns.</p>
<h4 id="the-problems-it-could-solve-1"><a class="header" href="#the-problems-it-could-solve-1">The problems it could solve</a></h4>
<p>Deep learning methods were incredibly successful at many tasks that were not possible to deal with earlier ones. Playing Go is much more complicated due to its branching factor (i.e., the number of possible states that the board can have at each move) compared to chess, and success was achieved much later. Another major success of deep learning was handwritten text recognition. There cannot be given a certain recipe for handwritten text, and it was possible only with deep learning so far, which could learn to recognize certain patterns in handwriting that could vary substantially from person to person. Even though not fully integrated with our lives yet because of some weaknesses of deep learning, self-driving cars are now easily imaginable and can actually be applied in constrained environments. This is also because neural networks can learn many different patterns for certain situations.</p>
<h4 id="the-problems-it-couldnt-solve--disadvantages"><a class="header" href="#the-problems-it-couldnt-solve--disadvantages">The problems it couldn’t solve – disadvantages</a></h4>
<p>Even though neural networks had unprecedented success with many tasks, they had their own shortcomings. The first is that they are not interpretable like previous, symbolic methods. For example, it is easy to understand how agents of behavioral AI do what they do. The explicit recipe given to them makes them interpretable at the same time. But for neural networks, this is not the case. It is not easy to understand how the weights take their final forms and what they mean, especially when the network is complex. Interpretability is important because it helps us understand why the agent makes mistakes and how we can improve them. Another drawback of neural networks is that they are not robust against some methods of deceit. For example, a neural network developed to label entities in images can be deceived by making small adjustments invisible to the human eye. But it is also possible to train neural networks that try to overcome these. Adversarial machine learning is the method of using two rival programs to compete against each other and get better and better at both deceiving and not falling into deceit.</p>
<p>One problem that might arise from the practical use of neural networks is related to data. Data and how it is processed is crucial, mistakes in data preprocessing can lead to bias and a decrease in performance. This might result in translations that are not representative of minorities, mistakenly labeling minorities as criminals, or not recognizing mirror reflections or images of objects in the real world, resulting in the AI making hazardous errors. One example of the errors that a deep learning agent can make is the driving assistant of Tesla, crashing into a truck because it confuses the bright white body of the truck with the sky<sup class="footnote-reference" id="fr-note4-1"><a href="#footnote-note4">4</a></sup>.</p>
<h2 id="compare-and-contrast-deep-learning-with-behavioral-ai-with-kuhns-account-of-science"><a class="header" href="#compare-and-contrast-deep-learning-with-behavioral-ai-with-kuhns-account-of-science">Compare and contrast Deep Learning with Behavioral AI with Kuhn’s Account of Science</a></h2>
<h3 id="periods-of-puzzle-solving"><a class="header" href="#periods-of-puzzle-solving">Periods of Puzzle-solving</a></h3>
<p>The behavioral AI period was marked by great success over many problems. The techniques that were developed made the field a much more mature one and the future looked bright. There was a period of puzzle-solving, “normal science” as named by Kuhn. There was a community of AI that was working, thinking, believing, and failing in the same way while doing AI research. Even though behavioral agents were very successful at certain tasks, in time, research on it ceased.</p>
<p>Researchers increasingly focused on deep learning, and the way that they worked, thought, believed, and failed changed. Most importantly, the problems that the researchers aimed to solve changed. The main problem of Behavioral AI is to create agents that would reactively engage within its environment and make decisions / behave according to certain preferences and to find the rules it would act according to for each problem. For deep learning, the main problem to be solved is to develop certain neural network architectures so that the agent could learn and represent information in the most accurate way possible to solve some problems without certain commands given by the researchers.</p>
<p>The puzzle-solving process shifted from being about how to maximize the utility function, how to make better decisions through better behavior structures, whether to use knowledgebases or not; to how to build a dataset, preprocess and utilize data better, how to arrange the architecture of the neural network better, and what kind of error or activation function to use and so on. Changes in the way of doing AI research seem to be captured by Kuhn’s account with distinct periods of puzzle-solving and normal science.</p>
<h3 id="the-two-ways-of-ai-research--normal-science-and-paradigm-development"><a class="header" href="#the-two-ways-of-ai-research--normal-science-and-paradigm-development">The Two Ways of AI Research – Normal Science and Paradigm Development</a></h3>
<p>Schmidhuber remarks on two of the ways of AI research. One is more practical and transient: To solve a problem that was not solved before, independent of developing a new tool or theory. Even though this would be considered a success, it would not take time until someone beats a more difficult version of the problem more efficiently. The second is theoretical: Developing a novel algorithm and proving that it is “optimal for an important class of AI problems”<sup class="footnote-reference" id="fr-note5-1"><a href="#footnote-note5">5</a></sup>.</p>
<p>The practical way resembles the normal science of Kuhn. Applying the novel techniques of the current paradigm to solve more difficult versions of some problems more efficiently or solve some previously unsolved problems. A behavioral agent could play chess and defeat world champions or could be programmed to play Atari games, but a deep learning agent would be able to defeat the behavioral agent at chess and learn by itself how to play all Atari games and excel at it. Under the new paradigm, researchers try to push the limits of the paradigm to solve similar but more difficult problems on a broader scale or solve previously unsolved problems.</p>
<p>From a Kuhnian perspective, this could be interpreted as the success of a new paradigm compared to the previous one’s attempts. Another Kuhnian aspect is that this way of research is the period of intense problem solving that is still going on right now. Deep learning is extremely popular, we see another success of AI application that was not seen before, in many different fields.</p>
<p>Still, there are unsolved problems (such as self-driving cars), but deep learning research continues until a better technique is found. And this highlights the second way of making AI research noted by Schmidhuber, which could resemble both normal science and the development of a new paradigm. Theorizing a new algorithm (of the current paradigm) to be optimal for a class of problems could extend the scope of the paradigm where previous paradigms could not reach, or it could be the development of a new, candidate paradigm.</p>
<h3 id="incommensurability-of-methods-and-theories-between-two-paradigms"><a class="header" href="#incommensurability-of-methods-and-theories-between-two-paradigms">Incommensurability of methods and theories between two paradigms</a></h3>
<p>In Kuhnian account of science, incommensurability refers to the condition that two paradigms do not communicate the same things, they do not fit together. Even though Newtonian physics can be seen as a special condition of modern physics, this is not the case. A simple example is that time and space are absolute in Newtonian physics, but not in modern physics. It is not important whether their predictions on some experiments are the same or not.</p>
<p>At the fundamentals of their theories, behavioral AI and deep learning are incommensurable. There is no place for perceptrons, multilayered architectures, backpropagation techniques, training with and learning from data in behavioral AI. Similarly, there is no utility function, modeling behavior, maximizing the preferences in deep learning. This also relates to their properties of being symbolic and sub-symbolic respectively. Phases of AI before deep learning are symbolic, the representation of information or rules is explicitly given. For example, an agent-based model is told that an apple is ‘an apple’. This enables the model to apply symbolic operations such as logic and search. Whereas in sub-symbolic AI, statistical methods of solving mathematical equations are more important. It is easier to understand symbolic AI, but sub- symbolic AI is much faster, more accurate, and more flexible.</p>
<p>But still, they can be used together in the same system. In practice, a deep learning agent can make use of a utility function as a supplement to its training phase or the rules for a behavioral agent can be found through deep learning approaches<sup class="footnote-reference" id="fr-note6-1"><a href="#footnote-note6">6</a></sup>. Incommensurability encompasses certain different aspects of the relationship between two paradigms. And the relationship between behavioral and deep learning approaches has a slight correspondence in Kuhnian incommensurability, but not completely.</p>
<h3 id="paradigm-shift"><a class="header" href="#paradigm-shift">Paradigm Shift</a></h3>
<p>The shift from each phase of AI to another marked a period of stagnation for AI research. In the case of the shift at hand, there are 18 years between the defeat of Kasparov by DeepBlue and of Lee Sedol by AlphaGo. Behavioral AI was successful in many fields: social sciences, business problems, etc. But it is limited since it requires explicit rules for each task, and rules for lots of tasks are too complicated to be captured exactly or in the best way possible. As researchers tackled problems using this approach, deep learning gained popularity, eventually becoming the dominant approach.</p>
<p>It is hard to mention a crisis in Kuhnian terms. Two earlier phases of AI study were not successful in what they aimed at; they could not go so far. Behavioral AI succeeded in the tasks it determined as a goal and had widespread use for many problems. Deep learning was not an alternative that was a savior for the crisis times. But it was so promising in its scope and success, that more and more researchers took up deep learning to tackle problems of AI. The paradigm shift occurred not through a crisis but more of the expectations from deep learning, and its fruitfulness.
Deep learning did solve lots of problems previously unsolved or not attempted, as well as solving lots of problems previous phases of AI did as well. In this sense, it does satisfy the Kuhnian paradigm shift in its promises and performance on previous problems.</p>
<h3 id="the-community-of-ai"><a class="header" href="#the-community-of-ai">The Community of AI</a></h3>
<p>Another Kuhnian aspect of this shift is that it was a social shift. Behavioral AI was not left behind (it is not completely left behind) because it was proved to be incorrect or failed completely. The community of AI believed in its success for a long time and could solve many problems using it. But deep learning looked more fruitful and took the stage lights from behavioral agents. The scientific community changed, and this change led to the shift in the two periods of research.</p>
<h2 id="discussion"><a class="header" href="#discussion">Discussion</a></h2>
<h3 id="is-ai-being-an-applied-science-an-obstacle"><a class="header" href="#is-ai-being-an-applied-science-an-obstacle">Is AI being an applied science an obstacle</a></h3>
<p>Of course, because AI is more of an applied field in its goals, it is hard to talk about incommensurability in the sense of meanings and explanations of phenomena. AI methods do not try to explain things, they try to perform tasks. Meanings of concepts in AI are fundamentally different than meanings of concepts in physics for example. The difference between the definitions of time in Newtonian and quantum physics is crucial because it aims to explain natural phenomena. AI (at least for now), does not aim to explain phenomena. Therefore incommensurability might not be applied completely to AI research.</p>
<p>Another point is that the success in AI approaches is defined differently compared to other fields of science. In other, more traditional fields of science, the theory at hand is used to make predictions under more or less controlled environments (of course, the reality is more complicated than that). The measure of success for AI is the performance of the agents in the tasks they are aiming to accomplish. This includes several metrics, such as how fast the model completes the task, how accurate it is, how well does it compete with other agents in the same task, how robust it is to certain changes in the environment, how complex is it, how easy it is to interpret the decisions of the agent, and so on. This actually helps us make choices depending on certain criteria, different from how Kuhnian paradigm choice happens.</p>
<h2 id="conclusion-1"><a class="header" href="#conclusion-1">Conclusion</a></h2>
<p>The history of the development of AI has many Kuhnian characteristics. The organization of research during the development phases of each period, how one ends, and another start, and how the communities of different approaches make their choices is well-captured by Kuhn’s account of science. And the shift from behavioral AI to deep learning can be explained to a certain degree too. But at its core, AI is a practical research field that aims to accomplish certain tasks instead of explaining phenomena. Therefore, it is hard to explain the shift from behavioral AI to deep learning completely with the Kuhnian account. Another account of science that can capture these differences of AI might be more successful than Kuhn’s. Nevertheless, this approach sheds light on how AI developed as a science and took its state today.</p>
<h2 id="references-1"><a class="header" href="#references-1">References</a></h2>
<hr>
<ol class="footnote-definition"><li id="footnote-note">
<p>Thomas S. Kuhn, The Structure of Scientific Revolutions (Chicago, IL: The University of Chicago Press, 2015). <a href="#fr-note-1">↩</a></p>
</li>
<li id="footnote-note2">
<p>S. T. Shenbagavalli and D. Shanthi, “A Study of Deep Learning: Architecture, Algorithm and Comparison,” Lecture Notes on Data Engineering and Communications Technologies, January 2019, pp. 385-391, https://doi.org/10.1007/978-3-030-24643-3_46. <a href="#fr-note2-1">↩</a></p>
</li>
<li id="footnote-note3">
<p>Kurt Hornik, Maxwell Stinchcombe, and Halbert White, “Multilayer Feedforward Networks Are Universal Approximators,” Neural Networks 2, no. 5 (1989): pp. 359-366, https://doi.org/10.1016/0893-6080(89)90020-8. <a href="#fr-note3-1">↩</a></p>
</li>
<li id="footnote-note4">
<p>Jordan Golson, “Tesla Driver Killed in Crash with Autopilot Active, NHTSA Investigating,” The Verge (The Verge, June 30, 2016), https://www.theverge.com/2016/6/30/12072408/tesla- autopilot-car-crash-death-autonomous-model-s. <a href="#fr-note4-1">↩</a></p>
</li>
<li id="footnote-note5">
<p>Jürgen Schmidhuber, “2006: Celebrating 75 Years of Ai - History and Outlook: The next 25 Years,” 50 Years of Artificial Intelligence, 2007, pp. 29-41, https://doi.org/10.1007/978-3-540-77296-5_4. <a href="#fr-note5-1">↩</a></p>
</li>
<li id="footnote-note6">
<p>Jäger, Georg. “Using Neural Networks for a Universal Framework for Agent-Based Models.” Mathematical and Computer Modelling of Dynamical Systems 27, no. 1 (2021): 162–78. https://doi.org/10.1080/13873954.2021.1889609. <a href="#fr-note6-1">↩</a></p>
</li>
</ol><div style="break-before: page; page-break-before: always;"></div><h1 id="day-one-dev-environment-camera-zoom-frame-rate-independence-mood-states"><a class="header" href="#day-one-dev-environment-camera-zoom-frame-rate-independence-mood-states">day one: dev environment, camera zoom, frame-rate independence, mood states</a></h1>
<p><strong>Date</strong>: 30.05.2025</p>
<p><strong>Session Duration</strong>: 10:00 - 14:00</p>
<h2 id="progress"><a class="header" href="#progress">Progress</a></h2>
<ol>
<li><strong>Environment</strong>
<ul>
<li>Migrated to Zed editor (AI features disabled for focused learning)</li>
<li>Ported project to updated Odin/Raylib template (Karl's latest)</li>
</ul>
</li>
<li><strong>Core Systems</strong>
<ul>
<li>Fixed camera zoom:
<ul>
<li>Always shows full game height</li>
<li>Window resize doesn't affect visible area in y axis</li>
</ul>
</li>
<li>Frame-rate independence:
<ul>
<li>Player never falls through platforms during resize</li>
<li>Physics stable at any FPS</li>
</ul>
</li>
</ul>
</li>
<li><strong>Mood System</strong>
<ul>
<li>Implemented mood states: <code>Sad | Angry | Inspired</code></li>
<li>Visual feedback:
<ul>
<li>Player tint (Red=Angry, Blue=Inspired, Gray=Sad)</li>
<li>Breakable walls highlight red when angry</li>
<li>Target tile highlights green (direction-facing)</li>
</ul>
</li>
<li>Special action bound to "E" key</li>
</ul>
</li>
</ol>
<h2 id="notes"><a class="header" href="#notes">Notes</a></h2>
<ul>
<li>Later on, I will need to fit the whole level to the window no matter what size. Is this called pixel perfection? Idk yet.</li>
<li>Right now, I don't have any system for collision detection, entities (<a href="https://floooh.github.io/2018/06/17/handles-vs-pointers.html">Handles are the better pointers
</a>), loading resources,</li>
</ul>
<h2 id="next-steps"><a class="header" href="#next-steps">Next Steps</a></h2>
<ul>
<li>Player state machine transition: <code>Grounded → Breaking</code> on "E" key press</li>
<li>Tile removal when broken</li>
<li>Breaking jump trajectory math</li>
<li>Letter data</li>
</ul>
<pre><code class="language-odin">Letter :: struct {
    id: int,
    content: string,
    mood: Mood,
    read_count: int,
    player_response: string,
}
</code></pre>
<ul>
<li>Storing level data in a better way, since current implementation is very limited</li>
</ul>
<pre><code>.........................
.........................
.........................
...............B.........
...............B.........
...............B.........
.........B.....B#........
.........B.....B#........
.........B##...B#........
.........B.....B#........
....L....B##...B#........
....#############........
....#....................
.S..#L............X......
#########################
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="day-two-automatic-hot-reload-smashing-jump-player-states"><a class="header" href="#day-two-automatic-hot-reload-smashing-jump-player-states">day two: automatic hot reload, smashing jump, player states</a></h1>
<p><strong>Date</strong>: 31.05.2025</p>
<p><strong>Session Duration</strong>: 18:00 - 20:30</p>
<h2 id="progress-1"><a class="header" href="#progress-1">Progress</a></h2>
<ol>
<li><strong>Automatic Hot Reloads</strong></li>
</ol>
<ul>
<li>
<p>using entr to automatically reload the game when source files change</p>
<p><code>find . -name "*.odin" | entr -c ./build_hot_reload.sh</code></p>
</li>
</ul>
<ol start="2">
<li><strong>Player States and Targeted Jump</strong></li>
</ol>
<ul>
<li>Added states for the player. The player can press E to jump and destroy a tile when angry.</li>
</ul>
<pre><code class="language-odin">PlayerState :: union {
	PlayerStateNormal,
	PlayerStateJumping,
	PlayerStateSmashing,
	PlayerStateDashing,
}

PlayerStateNormal :: struct {
}
PlayerStateJumping :: struct {
}
PlayerStateSmashing :: struct {
	smash_start_pos: Vec2,
	smash_progress:  f32,
	target_tile:     ^Tile,
	smash_peak:      Vec2,
}
</code></pre>
<h2 id="notes-1"><a class="header" href="#notes-1">Notes</a></h2>
<ul>
<li>I am not happy with the smashing jump trajectory math. I don't really understand the maths behind it and I don't like the way it looks.</li>
</ul>
<h2 id="next-steps-1"><a class="header" href="#next-steps-1">Next Steps</a></h2>
<ul>
<li>Handle based entity system</li>
<li>Letter data</li>
</ul>
<pre><code class="language-odin">Letter :: struct {
    id: int,
    content: string,
    mood: Mood,
    read_count: int,
    player_response: string,
}
</code></pre>
<ul>
<li>Storing level data in a better way, since current implementation is very limited</li>
</ul>
<pre><code>.........................
.........................
.........................
...............B.........
...............B.........
...............B.........
.........B.....B#........
.........B.....B#........
.........B##...B#........
.........B.....B#........
....L....B##...B#........
....#############........
....#....................
.S..#L............X......
#########################
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="day-three-handle-based-entity-system-reading-game-data-from-json"><a class="header" href="#day-three-handle-based-entity-system-reading-game-data-from-json">day three: handle-based entity system, reading game data from json</a></h1>
<p><strong>Date</strong>: 03.06.2025</p>
<p><strong>Session Duration</strong>: 11:00 - 17:00</p>
<h2 id="progress-2"><a class="header" href="#progress-2">Progress</a></h2>
<ol>
<li><strong>Handle-Based Entity System</strong>
I implemented Karl Zylinski's <a href="https://www.youtube.com/watch?v=MzR1us2nZPY">Static Handle Maps</a> for my entity system. I migrated my Player to be an Entity. The implementation isn't complete. I still need to migrate the animation, but that's another day's work.</li>
</ol>
<pre><code class="language-odin">Entity_Type :: enum {
	None,
	Player,
	Letter,
}

Entity_Type_Data :: union {
	Player_Data,
	Letter_Data,
}

Letter_Data :: struct {
	id:       string,
	response: string,
	content:  string,
	mood:     PlayerMood,
}

TextureName :: enum {
	Player,
	Letter,
}

Player_Data :: struct {
	state:         PlayerState,
	grounded:      bool,
	flipped:       bool,
	is_running:    bool,
	mood:          PlayerMood,
	idle_anim:     AnimatedSprite,
	run_anim:      AnimatedSprite,
	jump_anim:     AnimatedSprite,
	anim_instance: AnimationInstance,
}

Entity :: struct {
	handle:   Entity_Handle,
	type:     Entity_Type,
	pos:      Vec2,
	vel:      Vec2,
	size:     Vec2,
	color:    rl.Color,
	tex:      TextureName,
	// anim: Animation,
	collider: Rect,
	disabled: bool,
	data:     Entity_Type_Data,
}
</code></pre>
<ol start="2">
<li><strong>Reading Game Data From Json</strong>
I needed the letters to contain data, and my current ASCII-based level data can't support this. Therefore I decided to store these as JSON.</li>
</ol>
<p>Here is how I store the data for now:</p>
<pre><code class="language-json">{
  "data": [
    {
      "level_id": 1,
      "letters": [
        {
          "id": "1_1",
          "pos": [4, 10],
          "content": "A",
          "mood": "angry",
          "response": "I am angry!"
        },
        {
          "id": "1_2",
          "pos": [5, 13],
          "content": "B",
          "mood": "inspired",
          "response": "I am happy!"
        }
      ]
    }
  ]
}
</code></pre>
<p>And here is how I load it.</p>
<pre><code class="language-odin">LEVEL_COUNT :: 32
LETTER_COUNT :: 8

@(private = "file")
Letter_Data :: struct {
	id:       string,
	pos:      Vec2,
	content:  string,
	mood:     string,
	response: string,
}

@(private = "file")
Level_Data :: struct {
	level_id: int,
	letters:  [LETTER_COUNT]Letter_Data,
}

@(private = "file")
Level_Letter_Data :: struct {
	data: [LEVEL_COUNT]Level_Data,
}

parse_letter_data_json :: proc() -&gt; Level_Letter_Data {
	abs_path, _ := path.abs("./", context.temp_allocator)
	file_name := fmt.tprintf("%v/assets/levels/letter_data.json", abs_path)

	data, ok := os.read_entire_file_from_filename(file_name)
	if !ok {
		panic("Failed to load the letter data file!")
	}
	defer delete(data)

	level_letter_data: Level_Letter_Data
	unmarshal_err := json.unmarshal(data, &amp;level_letter_data, allocator = context.temp_allocator)
	if unmarshal_err != nil {
		panic("Failed to unmarshal letter json file!")
	}

	return level_letter_data
}
</code></pre>
<h2 id="notes-2"><a class="header" href="#notes-2">Notes</a></h2>
<ul>
<li>The structure of all this could change. I am still learning and figuring out how to do things.</li>
<li>I am slightly aware that I could optimize game data loading by storing them as binary, since parsing JSON is slow. Maybe I do that as a pre-compilation step. But I think my game is too small for this.</li>
</ul>
<h2 id="next-steps-2"><a class="header" href="#next-steps-2">Next Steps</a></h2>
<ul>
<li>Mood-based abilities (Still need to implement Inspired and Sad mood abilities. I think I'll do Sad the latest because it requires me to implement disabling collision temporarily)</li>
<li>Collecting letters, displaying letter content</li>
<li>One way platforms</li>
<li>A second level that has one way platforms, and an animated enemy</li>
<li>Level transitions</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="day-four-letter-ui-scaling-the-ui-displaying-collected-letters-and-disabling-input"><a class="header" href="#day-four-letter-ui-scaling-the-ui-displaying-collected-letters-and-disabling-input">day four: letter ui, scaling the ui, displaying collected letters and disabling input</a></h1>
<p><strong>Date</strong>: 06.06.2025</p>
<p><strong>Session Duration</strong>: 16:00 - 18:00</p>
<h2 id="progress-3"><a class="header" href="#progress-3">Progress</a></h2>
<ol>
<li><strong>Letter UI</strong>
I list collected letters as UI elements on the top left of my screen. Later on, I will use their indices for player to re-read them. I also made a simple UI for the letter that displays the content and frames it with the color of the mood. I wrote very basic code, so there is a lot of duplication for the paddings.</li>
</ol>
<p>When the player collects a letter, it is set as the active letter. For this, I added a new state to the player: PlayerStateReadingLetter. While in this state, the ui draws the letter</p>
<pre><code class="language-odin">PlayerState :: union #no_nil {
	PlayerStateNormal,
	PlayerStateJumping,
	PlayerStateSmashing,
	PlayerStateDashing,
	PlayerStateReadingLetter,
}

PlayerStateReadingLetter :: struct {
	active_letter: Entity_Handle,
}
</code></pre>
<ol start="2">
<li><strong>Disabling Input</strong>
I disabled all input except for Enter while reading letter. I did this very brutally for now</li>
</ol>
<pre><code class="language-odin">player := hm.get(&amp;g_mem.entities, g_mem.player)
	player_data, _ := player.data.(Player_Data)
	if _, ok := player_data.state.(PlayerStateReadingLetter); ok {
		input = {
			enter = input.enter,
		}
	}
</code></pre>
<ol start="3">
<li><strong>Scaling the UI</strong>
I had to do quite a bit of UI programming. The UI had to be scaled for the user's screen size, and things got messy in the beginning. But I figured it out.</li>
</ol>
<h2 id="notes-3"><a class="header" href="#notes-3">Notes</a></h2>
<ul>
<li>I really don't think this code is going to scale. Getting the player entity takes too much effort every time because I am just using the bare-bones handle map functions. I should write a function to get it easily.</li>
<li>I might need a simple system for layouts, paddings, margins, and alignment.</li>
</ul>
<h2 id="next-steps-3"><a class="header" href="#next-steps-3">Next Steps</a></h2>
<ul>
<li>Mood-based abilities (Still need to implement Inspired and Sad mood abilities. I think I'll do Sad the latest because it requires me to implement disabling collision temporarily)</li>
<li>One way platforms</li>
<li>A second level that has one way platforms, and an animated enemy</li>
<li>Level transitions</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
